{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import re\r\n",
    "\r\n",
    "from sqlalchemy import create_engine\r\n",
    "import psycopg2\r\n",
    "\r\n",
    "# from config import db_password\r\n",
    "\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 1. Add the clean movie function that takes in the argument, \"movie\".\r\n",
    "def clean_movie(movie):\r\n",
    "    movie = dict(movie) # Convert list item to a dict\r\n",
    "    alt_titles = {} # Initialize a dictionary to hold alt titles\r\n",
    "    \r\n",
    "    # Column headers that could hold alt titles\r\n",
    "    alt_keys = ['Also known as', 'Arabic', 'Cantonese', 'Chinese', 'French', 'Hangul', 'Hebrew', 'Hepburn', 'Japanese', \r\n",
    "                'Literally', 'Mandarin', 'McCune–Reischauer', 'Original title', 'Polish', 'Revised Romanization', \r\n",
    "                'Romanized', 'Russian', 'Simplified', 'Traditional', 'Yiddish']\r\n",
    "    \r\n",
    "    # Check each key for data\r\n",
    "    for key in alt_keys:\r\n",
    "\r\n",
    "        # If data exists in current key, add it to alt titles dict and remove it from movie dict\r\n",
    "        if key in movie: \r\n",
    "            alt_titles[key] = movie[key]\r\n",
    "            movie.pop(key)\r\n",
    "\r\n",
    "    # If current movie contains alt titles, add them under alt_titles key to original dict\r\n",
    "    if len(alt_titles) > 0:\r\n",
    "        movie['alt_titles'] = alt_titles\r\n",
    "\r\n",
    "    # Create a function that will combine like-columns based on the tuple \"names\"\r\n",
    "    def change_column_name(names):\r\n",
    "        if names[0] in movie:\r\n",
    "            movie[names[1]] = movie.pop(names[0])\r\n",
    "\r\n",
    "    # A list of tuples that will be passed to the change_column_name function. First entry is old name, second is new name.\r\n",
    "    columns_to_change = [\r\n",
    "        ('Adaptation by', 'Writer(s)'),\r\n",
    "        ('Screen story by', 'Writer(s)'),\r\n",
    "        ('Screenplay by', 'Writer(s)'),\r\n",
    "        ('Story by', 'Writer(s)'),\r\n",
    "        ('Written by', 'Writer(s)'),\r\n",
    "        ('Adaptation by', 'Writer(s)'),\r\n",
    "        ('Country of origin', 'Country'),\r\n",
    "        ('Directed by','Director(s)'),\r\n",
    "        ('Director','Director(s)'),\r\n",
    "        ('Created by', 'Creator(s)'),\r\n",
    "        ('Distributed by','Distributor(s)'),\r\n",
    "        ('Distributor','Distributor(s)'),\r\n",
    "        ('Edited by', 'Editor(s)'),\r\n",
    "        ('Length', 'Running time'),\r\n",
    "        ('Music by', 'Composer(s)'),\r\n",
    "        ('Original release', 'Release date'),\r\n",
    "        ('Produced by', 'Producer(s)'),\r\n",
    "        ('Producer', 'Producer(s)'),\r\n",
    "        ('Production company(s)', 'Production compan(ies)'),\r\n",
    "        ('Productioncompanies ', 'Production compan(ies)'),\r\n",
    "        ('Productioncompany ', 'Production compan(ies)'),\r\n",
    "        ('Released', 'Release date'),\r\n",
    "        ('Theme music composer', 'Composer(s)')\r\n",
    "    ]\r\n",
    "\r\n",
    "    [change_column_name(names) for names in columns_to_change]\r\n",
    "\r\n",
    "    return movie"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 2 Add the function that takes in three arguments;\r\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\r\n",
    "\r\n",
    "def movies_ETL():\r\n",
    "    # Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\r\n",
    "    kaggle_metadata = pd.read_csv('Resources/movies_metadata.csv', low_memory=False)\r\n",
    "    ratings = pd.read_csv('Resources/ratings.csv')\r\n",
    "\r\n",
    "    # Open and read the Wikipedia data JSON file.\r\n",
    "    with open('Resources/wikipedia-movies.json', mode='r') as file:\r\n",
    "        wiki_movies = json.load(file)\r\n",
    "    \r\n",
    "    # 3. Write a list comprehension to filter out TV shows.\r\n",
    "    wiki_movies = [movie for movie in wiki_movies if 'No. of episodes' not in movie]\r\n",
    "\r\n",
    "    # 4. Write a list comprehension to iterate through the cleaned wiki movies list\r\n",
    "    # and call the clean_movie function on each movie.\r\n",
    "    clean_wiki_movies = [clean_movie(movie) for movie in wiki_movies]\r\n",
    "\r\n",
    "    # 5. Read in the cleaned movies list from Step 4 as a DataFrame.\r\n",
    "    wiki_movies_df = pd.DataFrame(clean_wiki_movies)\r\n",
    "\r\n",
    "    # 6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\r\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\r\n",
    "    try:\r\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\r\n",
    "        wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "\r\n",
    "    #  7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\r\n",
    "    columns_to_keep = [col for col in wiki_movies_df.columns if wiki_movies_df[col].isnull().sum() < len(wiki_movies_df)]\r\n",
    "    wiki_movies_df = wiki_movies_df[columns_to_keep]\r\n",
    "\r\n",
    "    # 8. Create a variable that will hold the non-null values from the “Box office” column.\r\n",
    "    box_office = wiki_movies_df['Box office'].dropna()\r\n",
    "    \r\n",
    "    # 9. Convert the box office data created in Step 8 to string values using the lambda and join functions.\r\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\r\n",
    "\r\n",
    "    # 10. Write a regular expression to match the six elements of \"form_one\" of the box office data.\r\n",
    "    form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\r\n",
    "\r\n",
    "    # 11. Write a regular expression to match the three elements of \"form_two\" of the box office data.\r\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\r\n",
    "\r\n",
    "    # 12. Add the parse_dollars function.\r\n",
    "    def parse_dollars(s):\r\n",
    "    # if s is not a string, return NaN\r\n",
    "        if type(s) != str:\r\n",
    "            return np.nan\r\n",
    "\r\n",
    "        # if input is of the form $###.# million\r\n",
    "        if re.match(r\"\\$\\s*\\d+\\.?\\d*\\s*milli?on\", s, flags=re.IGNORECASE):\r\n",
    "            # remove the $ and million\r\n",
    "            s = re.sub(r'\\$|\\s|[a-zA-Z]','', s)\r\n",
    "            # convert to float and multiply my a million\r\n",
    "            s = float(s) * 10 ** 6\r\n",
    "            # return value\r\n",
    "            return s\r\n",
    "        # if input is of the form $###.# billion\r\n",
    "        elif re.match(r\"\\$\\s*\\d+\\.?\\d*\\s*billi?on\", s, flags=re.IGNORECASE):\r\n",
    "            # remove the $ and billion\r\n",
    "            s = re.sub(r'\\$|\\s|[a-zA-Z]', '', s)\r\n",
    "            # convert to float and multiply my a billion\r\n",
    "            s = float(s) * 10 ** 9\r\n",
    "            # return value\r\n",
    "            return s\r\n",
    "        # if input is of the form $###,###,###\r\n",
    "        elif re.match(form_two, s):\r\n",
    "            # Remove the $ and ,\r\n",
    "            s = re.sub(r'\\$|,', '', s)\r\n",
    "            # convert to float\r\n",
    "            s = float(s)\r\n",
    "            # return value\r\n",
    "            return s\r\n",
    "        # otherwise, return NaN\r\n",
    "        else:\r\n",
    "            return np.nan\r\n",
    "        \r\n",
    "    # 13. Clean the box office column in the wiki_movies_df DataFrame.\r\n",
    "    wiki_movies_df['Box office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\r\n",
    "    \r\n",
    "    # 14. Clean the budget column in the wiki_movies_df DataFrame.\r\n",
    "    wiki_movies_df['Budget'] = wiki_movies_df.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\r\n",
    "\r\n",
    "    # 15. Clean the release date column in the wiki_movies_df DataFrame.\r\n",
    "    \r\n",
    "\r\n",
    "    # 16. Clean the running time column in the wiki_movies_df DataFrame.\r\n",
    "    \r\n",
    "    # Return three variables. The first is the wiki_movies_df DataFrame\r\n",
    "    \r\n",
    "    return wiki_movies_df, kaggle_metadata, ratings "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 17. Create the path to your file directory and variables for the three files.\r\n",
    "file_dir = \r\n",
    "# The Wikipedia data\r\n",
    "wiki_file = f'{file_dir}/wikipedia.movies.json'\r\n",
    "# The Kaggle metadata\r\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\r\n",
    "# The MovieLens rating data.\r\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 18. Set the three variables equal to the function created in D1.\r\n",
    "wiki_file, kaggle_file, ratings_file = extract_transform_load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 19. Set the wiki_movies_df equal to the wiki_file variable. \r\n",
    "wiki_movies_df = wiki_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 20. Check that the wiki_movies_df DataFrame looks like this. \r\n",
    "wiki_movies_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 21. Check that wiki_movies_df DataFrame columns are correct. \r\n",
    "wiki_movies_df.columns.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('PythonData': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "31e5de16cd2653dab55601d1a8dbb65d5bfcb5e37c58103bf717bd42fcbdf8d3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}